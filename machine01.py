#!/usr/bin/python

'''
Code by Alex Masluk
Used techniques learned from scikit-learn.org tutorials @ http://scikit-learn.org/stable/tutorial/index.html
Obtained .coef_ and .intercept_ from pipeline obj by following example @ 
    https://stackoverflow.com/questions/28822756/getting-model-attributes-from-scikit-learn-pipeline
'''

import scipy.io as sio
import numpy as np
import matplotlib.pyplot as plt
import sklearn.linear_model as lin
from sklearn.metrics import mean_squared_error as mse
from sklearn.preprocessing import PolynomialFeatures as poly
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import LeaveOneOut

def load_data():
    '''Experiment 1
    Load olympic data
    Return dict
    '''
    return sio.loadmat('olympics.mat')

def year_time_graph(olympics, dataset, fit_line=0):
    '''Experiments 2 and 4
    Reproduce figures 1.1 and 1.5 from textbook
    '''
    data = olympics[dataset]
    year,time = data[:,0],data[:,1]
    plt.plot(year,time, 'bo')
    if fit_line == 1:
        fit_model = order1_linear_regression(olympics, dataset)
        plt.plot([1895,2010], [fit_model.predict(1895), fit_model.predict(2010)])
    if dataset == 'male100':
        plt.axis([1880,2020,9.5,12])

    plt.xlabel('Year')
    plt.ylabel('Time (seconds)')
    print('Please close the graph to continue...')
    plt.show()

def order1_linear_regression(olympics, dataset):
    '''Perform first-order linear regression
    Params: the olympics.dat datasets, the name of dataset on which to do LR
    Return the LR fit object
    '''
    lr = lin.LinearRegression()
    dat = olympics[dataset]
    x = dat[:,0].reshape(-1,1)
    y = dat[:,1]
    return lr.fit(x,y)

def get_regression_model(olympics, dataset, degree=1, model=lin.LinearRegression()):
    '''Perform n-order regression
    Params: the olympics datasets, name of dataset to do regression on, polynomial degree, regression type
    Returns pipeline object
    '''
    dat = olympics[dataset]
    x = dat[:,0].reshape(-1,1)
    y = dat[:,1]
    mod = make_pipeline(poly(degree), model)
    return mod.fit(x,y)

def print_coefs(model_type, model):
    '''Print coefficients and intercepts of a regression model
    Param: regression type, regression model
    '''
    model_type = str(model_type)[0:str(model_type).find('(')]
    print('regression = {}'.format(model_type))
    print('coef: ')
    for x,coef in enumerate(model.steps[1][1].coef_):
        print('\t{} * x^{}'.format(str(coef).ljust(18), x))
    print('intr: {}'.format(model.steps[1][1].intercept_))
    print('')


def test_regression_model(olympics, test_type=1, degree=1, compare=None):
    '''Experiments 3, 5, 6, 7
    Evaluate linear regression model(s) and display results
    Params: Olympics datasets, test to perform, polynomial degree, previous value for comparison
    Return value for future comparison
    '''

    # Occasionally we want to remember a value from our tests
    # This gets returned
    value = None
    if test_type == 1:
        # Experiment 3: display coefficients and predictions
        # Compare results with Section 1.2
        model = get_regression_model(olympics, 'male100', 1)
        print_coefs(lin.LinearRegression(), model)

        # Textbook values for comparison
        Y1, Y2 = 9.595, 9.541
        x1, x2 = 2012, 2016

        # Values generated by our model
        y1 = round(float(model.predict(x1)), 3)
        y2 = round(float(model.predict(x2)), 3)

        print("Predictions:")
        print("f({}) = {}".format(x1,y1))
        print("f({}) = {}".format(x2,y2))
        print("Comparison ( expected == actual? ): #expected values from textbook")
        print("{} == {}? {}".format(Y1, y1, Y1 == y1))
        print("{} == {}? {}".format(Y2, y2, Y2 == y2))
        '''expected output:
        regression = LinearRegression
        coef:
                0.0                * x^0
                -0.013330885711    * x^1
        intr: 36.4164559025

        Predictions:
        f(2012) = 9.595
        f(2016) = 9.541
        Comparison ( expected == actual? ): #expected values from textbook
        9.595 == 9.595? True
        9.541 == 9.541? True

        '''


    if test_type == 2:
        # Experiment 5: fit a line to female400
        # Compare error with error from male100

        # X vectors
        m_x_vector = olympics['male100'][:,0].reshape(-1,1)
        f_x_vector = olympics['female400'][:,0].reshape(-1,1)

        # Actual values
        m_actual = olympics['male100'][:,1]
        f_actual = olympics['female400'][:,1]

        # Linear regression models
        #  Note: for some reason using get_regression_model on male100 doesn't work!
        model_m = order1_linear_regression(olympics, 'male100')
        model_f = get_regression_model(olympics, 'female400')

        # Predicted values
        m_pred = model_m.predict(m_x_vector)
        f_pred = model_f.predict(f_x_vector)

        # Mean squared error for both sets
        m_error = mse(m_actual, m_pred)
        f_error = mse(f_actual, f_pred)

        # Display results
        print("male100 mse  : {}".format(m_error))
        print("female400 mse: {}".format(f_error))
        print("female_mse - male_mse = {}".format(abs(f_error - m_error)))
        '''expected output:
        male100 mse  : 0.0503071104757
        female400 mse: 0.848981206294
        female_mse - male_mse = 0.798674095818
        '''
        value = f_error

    if test_type == 3:
        # Experiment 6, 7
        # Fit an N order polynomial to female400. Does the error improve?

        # Get the model
        poly_model = get_regression_model(olympics, 'female400', degree)

        # X vector and actual values
        x_vector = olympics['female400'][:,0].reshape(-1,1)
        actual = olympics['female400'][:,1]

        # Prediction set and mean squared error
        p_pred = poly_model.predict(x_vector)
        poly_error = mse(actual, p_pred)

        # Display results
        # For experiment 6, error improves substantially
        # For experiment 7, error improves slightly
        print("{}-degree error: {}".format(degree, poly_error))
        print("Previous error:  {}".format(compare))
        print("Current error < previous error? {}".format(poly_error < compare))
        print("Diff = {}".format(abs(poly_error - compare)))
        '''expected output:
        experiment 6:
        3-degree error: 0.134244240949
        Previous error:  0.848981206294
        Current error < previous error? True
        Diff = 0.714736965345

        experiment 7:
        5-degree error: 0.134210747781
        Previous error:  0.134244240949
        Current error < previous error? True
        Diff = 3.34931681457e-05
        '''
        value = poly_error



    raw_input("Please hit enter to continue...")
    return value

def loocv(olympics, dataset='female400'):
    '''Experiment 8
    Use LOOCV for both 3rd and 5th order polynomials.
    Determine which is a better choice
    Params: the olympic datasets
    '''
    # 5th order is the better polynomial
    lr = lin.LinearRegression()

    for order in [3,5]:
        dat = olympics[dataset]
        x = dat[:,0].reshape(-1,1)
        y = dat[:,1]
        loo = LeaveOneOut()
        cumulative_error = 0
        best_avg = -1


        for train, validate in loo.split(x):
            model = make_pipeline(poly(order), lr)

            # linear model based on training set
            fit = model.fit(x[train], y[train])
            # validate with the one left out
            cumulative_error += (y[validate] - fit.predict(x[validate])) ** 2

        avg = cumulative_error / loo.get_n_splits(x)
        print('avg error for order {}={}'.format(order, avg))
        if best_avg < 0 or best_avg > avg:
            best_avg = avg
            best_order = order

    print('best polynomial order={}'.format(best_order))
    '''expected output:
    avg error for order 3=[ 0.56244516]
    avg error for order 5=[ 0.5575277]
    best polynomial order=5
    '''
    raw_input("Please hit enter to continue...")

def test_ridge(olympics, dataset='female400'):
    '''Experiment 9
    Use 5th order ridge regression and compare with
    fifth order linear regression coefficients
    '''

    # There doesn't seem to be a strong correlation between the coefs
    # found by each model
    for model in [lin.LinearRegression(), lin.Ridge()]:
        mod  = get_regression_model(olympics, dataset, 5, model)
        print_coefs(model, mod)
        '''expected output:
        regression = LinearRegression
        coef:
            0.0
            -1.05956071161e-10
            -8.33691892654e-09
            -8.27841353853e-06
            5.60964271729e-09
            -1.001102718e-12
        intr: 8557.19887606

        regression = Ridge
        coef:
            0.0
            6.35641246518e-06
            0.00630479781012
            -1.46277631637e-05
            8.007421312e-09
            -1.32305207396e-12
        intr: 6070.68047427
        '''

def ridgecv(olympics, dataset='female400'):
    '''Experiment 10
    Use RidgeCV to find best alpha value
    '''

    # 1.0 turns out to be the best alpha
    alphas = [0.001, 0.002, 0.004, 0.01, 0.02, 0.04, 0.1, 0.2, 0.4, 1.0]
    ridge = lin.RidgeCV(alphas)
    x_vector = olympics['female400'][:,0].reshape(-1,1)
    actual = olympics['female400'][:,1]
    ridge.fit(x_vector, actual)
    print('alpha={}'.format(ridge.alpha_))
    '''expected output:
    alpha=1.0
    '''









def main():
    print("Experiment 1: Load the data")
    olympics = load_data()
    print("Data loaded: type(olympics) = {}".format(type(olympics)))
    print('')

    print("Experiment 2: Reproduce figure 1.1")
    year_time_graph(olympics, 'male100')
    print('')

    print("Experiment 3: Get linear regression model for male100")
    print("              List coefficients and compare predictions")
    test_regression_model(olympics, 1)
    print('')

    print("Experiment 4: Reproduce figure 1.5")
    year_time_graph(olympics, 'male100', 1)
    print('')

    print("Experiment 5: Get linear regression model for female400")
    print("              Compare error with model for male100")
    error = test_regression_model(olympics, 2)
    print('')

    print("Experiment 6: Fit a 3rd degree polynomial to female400")
    print("              Does the error improve?")
    error = test_regression_model(olympics, 3, degree=3, compare=error)
    print('')


    print("Experiment 7: Fit a 5th degree polynomial to female400")
    print("              Does the error improve?")
    test_regression_model(olympics, 3, degree=5, compare=error)
    print('')

    print("Experiment 8: Use LOOCV for 3rd and 5th order polys")
    print("              Which is better?")
    loocv(olympics)
    print('')

    print("Experiment 9: Compare 5th order Ridge regression coefs with linear")
    test_ridge(olympics)
    print('')

    print("Experiment 10: Find best value for alpha using RidgeCV")
    ridgecv(olympics)
    print('')

if __name__ == '__main__':
    main()
